{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# load the required libraries\n\n# Basic algebra and matrix mathematics libraries\nimport numpy as np\nimport pandas as pd\n\n# Basic visualization libraries\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n\n# Basic image manipulation libraries\nimport imageio\nimport cv2\nfrom skimage.transform import rescale, resize, rotate\nfrom skimage.color import rgb2gray\nfrom sklearn.metrics import confusion_matrix, auc, accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# Libraries to build and test the neural network\nimport tensorflow as tf\nfrom keras import models\nfrom keras import callbacks\nimport pickle\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.optimizers import Adam,SGD,RMSprop\nfrom keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nrandom_state = 42\n\n# Setting a random state for reproducibility\nimport random\nnp.random.seed(random_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib \nprint(device_lib.list_local_devices())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the data into a pandas dataframe and have a look at it\nraw_data = pd.read_csv('/kaggle/input/honey-bee-annotated-images/bee_data.csv')\nraw_data.head()\n\n# get value counts of the number of health conditions\nraw_data.health.value_counts(normalize = True)\n\n# there are too many categories in the unhealthy bees, it would be better if they are all taken as one class - 'unhealthy'\n# this will solve the obvious imbalance in data as well\nhealth_counts = raw_data.health.value_counts()\nhealth_counts\n\n# if a row has its health set to anything other than \"healthy\", set it to unhealthy\n# now we have only 2 classes - healthy or unhealthy\nraw_data.loc[raw_data.health != 'healthy','health'] = 0 #unhealthy\nraw_data.loc[raw_data.health == 'healthy','health'] = 1 #healthy\nraw_data.head()\n\n# let us check the distribution of values\n# As we can see, there is a 65/35 distribution between the classes which is not so skewed\nraw_data.health.value_counts(normalize = True)\n\n# we only need the filename and the health condition of the bees so we can drop the other columns\nraw_data.drop(columns=['date','time','location','zip code','subspecies','pollen_carrying','caste'], inplace=True)\n\n# check out the changed dataframe\nraw_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in all the images and store them as np arrays\n# Make sure all images are read as greyscale which makes computations easy for the neural network\n# It also reduces errors which arise from it learning background color\n# Define a function which fetches an image from the specified path based on\n# an argument which is the name of the file in str format\ndef FetchImage(filename):\n    # Define the path of the images\n    IMAGE_FILE_ROOT = '/kaggle/input/honey-bee-annotated-images/bee_imgs/bee_imgs/'\n    return cv2.imread(IMAGE_FILE_ROOT+filename, cv2.IMREAD_GRAYSCALE)\n\n\n# use the function to get image data and store it inside an np array\nimage_data_array = list()\nfor i in range(raw_data.shape[0]):\n    image_data_array.append(FetchImage(raw_data.file.values[i]))\n\nimage_data_array = np.asarray(image_data_array)\n\n# check out a random image\nplt.imshow(image_data_array[42])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now need to resize the images such that they can be input to the neural net\n# in a consistent manner. The most ideal size is (54, 50) - experimentation\n# we set the image height and width and resize it using OpenCV's resize function\n# we also normalize the images between 0 and 1 to signify brightness of the pixels\ndef normalize(image):\n    im_width = 54\n    im_height = 50\n    dsize = (im_width, im_height)\n    resized = cv2.resize(image, dsize)\n\n    return ((resized/255.0))\n\n\ndef create_datagens(data, datagen_params, target_shape, batch_size, random_state = 42, preprocessing_function = None, x_col=\"file\", y_col=\"health\", IMAGE_FILE_ROOT = '/kaggle/input/honey-bee-annotated-images/bee_imgs/bee_imgs/'):\n    data[y_col] = data[y_col].astype(str) # coercion needed for datagen\n    # train/test split\n    train, test = train_test_split(data,test_size = 1/3,\n    stratify = data.iloc[:,-1], # assumed last column is target variable\n    random_state = random_state)\n\n    # training ImageDataGenerator\n    datagen = ImageDataGenerator(horizontal_flip  = datagen_params.get(\"horizontal_flip\") or False,\n    vertical_flip = datagen_params.get(\"vertical_flip\") or False,\n    rotation_range   = datagen_params.get(\"rotation_range\") or False,\n    brightness_range = datagen_params.get(\"brightness_range\"),\n    preprocessing_function = preprocessing_function)\n\n    datagen_iter_train = datagen.flow_from_dataframe(train,\n    directory = IMAGE_FILE_ROOT,\n    x_col = x_col,\n    y_col = y_col,\n    target_size = target_shape,\n    class_mode = 'binary',\n    batch_size = batch_size,\n    shuffle = True,\n    seed = random_state)\n\n    # testing ImageDataGenerator\n    datagen_test = ImageDataGenerator(preprocessing_function = preprocessing_function)\n    datagen_iter_test = datagen_test.flow_from_dataframe(test,\n    directory = IMAGE_FILE_ROOT,\n    x_col = x_col,\n    y_col = y_col,\n    target_size = target_shape,\n    class_mode  = 'binary',\n    batch_size  = 1,\n    shuffle = False)\n\n    return datagen_iter_train, datagen_iter_test\n\n\ndef permutate_params(grid_params):\n    '''Returns a list of all combinations of unique parameters from the given dictionary'''\n    out = [{}]\n\n    # loop through each key/val pair\n    for param_name, param_list in grid_params.items():\n        # shortcircut - no need to permute single items\n        if len(param_list) == 1:\n            for item in out:\n                item[param_name] = param_list[0]\n        else:\n            temp_out = []\n            # for each item in the param, clone entire growing list and add param to each\n            for param_val in param_list:\n                for item in out:\n                    cloned_item = item.copy()\n                    cloned_item[param_name] = param_val\n                    temp_out.append(cloned_item)\n            out = temp_out\n    return out\n\n\ndef build_model_from_datagen(params = dict(),input_shape = (),datagen_iter_train = None,datagen_iter_val = None,file_name = None, optimizer = \"adam\"):\n    kernel_size = 3\n    dropout = .5\n    activation_func = \"relu\"\n\n    conv__filters_1 = params.get('conv__filters_1') or 32\n    conv__filters_2 = params.get('conv__filters_2') or 16\n    conv__filters_3 = params.get('conv__filters_3') or 32\n    density_units_1 = params.get('density_units_1') or 32\n    density_units_2 = params.get('density_units_2') or 32\n    epochs          = params.get('epochs') or 10\n\n    # instantiating model\n    model = Sequential([\n        # Conv layer #1\n        Conv2D(\n            filters = conv__filters_1,\n            kernel_size = kernel_size + 4,\n            activation  = activation_func,\n            input_shape = input_shape, #input layer\n            padding     = \"same\"\n        ),\n        Conv2D(filters = conv__filters_1, kernel_size = kernel_size + 4, activation = activation_func, padding = \"same\"),\n        MaxPooling2D(pool_size=(2,2)),\n        Dropout(dropout/2),\n\n        # Conv layer #2\n        Conv2D(filters = conv__filters_2, kernel_size = kernel_size + 2, activation=activation_func, padding = \"same\"),\n        Conv2D(filters = conv__filters_2, kernel_size = kernel_size + 2, activation = activation_func, padding = \"same\"),\n        MaxPooling2D(pool_size=(2,2)),\n        Dropout(dropout/2),\n\n        # Conv layer #3\n        Conv2D(filters = conv__filters_3, kernel_size = kernel_size, activation=activation_func, padding = \"same\"),\n        Conv2D(filters = conv__filters_3, kernel_size = kernel_size, activation = activation_func, padding = \"same\"),\n        MaxPooling2D(pool_size=(2,2)),\n        Dropout(dropout/2),\n\n        # Dense layer #1\n        Flatten(),\n        Dense(density_units_1, activation=activation_func),\n        Dropout(dropout),\n\n        # Dense layer #2\n        Dense(density_units_2, activation=activation_func),\n        Dropout(dropout),\n\n        # Output layer\n        Dense(1, activation='sigmoid')\n    ])\n\n    # compiling model\n    model.compile(\n        loss      = 'binary_crossentropy',\n        optimizer = optimizer,\n        metrics   = ['binary_accuracy']\n    )\n\n    # fitting model w/ImageDataGenerator\n    STEP_SIZE_TRAIN= np.ceil(datagen_iter_train.n/datagen_iter_train.batch_size)\n    STEP_SIZE_VALID= np.ceil(datagen_iter_val.n/datagen_iter_val.batch_size)\n\n    # NOTE: the best model is saved to disk via callbacks, and is a retrievable file\n    history = model.fit_generator(\n        generator           = datagen_iter_train,\n        steps_per_epoch     = STEP_SIZE_TRAIN,\n        validation_data     = datagen_iter_val,\n        validation_steps    = STEP_SIZE_VALID,\n        epochs              = epochs,\n        callbacks           = [callbacks.ModelCheckpoint(file_name, save_best_only=True, mode='auto', period=1)]\n    )\n\n    return (model, history)\n\n\n\ndef gridSearchCNN(datagens,grid_params,file_name,random_state = None,optimizer = \"adam\",):\n    # list of all parameter combinations\n    all_params = permutate_params(grid_params)\n\n    # establishing variables\n    best_model   = None\n    best_score   = 0.0 # no accuracy to start\n    best_params  = None\n    best_history = None\n    test_scores  = None\n    train_scores = None\n\n    datagen_iter_train, datagen_iter_test = datagens\n\n    # for each permuted parameter, try fitting a model (NOTE: the best model is saved to disk with file_name)\n    for params in all_params:\n        model, history = build_model_from_datagen(\n            params,\n            input_shape        = datagen_iter_train.image_shape,\n            datagen_iter_train = datagen_iter_train,\n            datagen_iter_val   = datagen_iter_test,\n            optimizer          = optimizer,\n            file_name          = file_name\n        )\n\n        acc = max(history.history[\"val_binary_accuracy\"])\n\n        # only keeping best\n        if acc > best_score:\n            print(\"***Good Accurary found: {:.2%}***\".format(acc))\n            best_score   = acc\n            test_scores  = history.history[\"val_binary_accuracy\"]\n            train_scores = history.history[\"binary_accuracy\"]\n            best_model   = model\n            best_params  = params\n            best_history = history\n\n    # returns metadata of results (NOTE: retrieving best model from hard disk)\n    return {\n        \"best_model\"   : load_model(file_name),\n        \"best_score\"   : best_score,\n        \"best_params\"  : best_params,\n        \"best_history\" : best_history,\n        \"test_scores\"  : test_scores,\n        \"train_scores\" : train_scores\n    }\n\n\n\ndef conf_matrix_stats(y_test, preds):\n    ''' Return key confusion matrix metrics given true and predicted values'''\n    cm = confusion_matrix(y_test, preds)\n    TP, FP, FN, TN, = cm[1,1], cm[0,1], cm[1,0], cm[0,0]\n    total = (TP + FP + FN + TN)\n    acc = (TP + TN ) / total\n    miss = 1 - acc\n    sens = TP / (TP + FN)\n    spec = TN / (TN + FP)\n    prec = TP / (TP + FP)\n    return {\"accuracy\": acc, \"miss_rate\": miss, \"sensitivity\": sens, \"specification\": spec, \"precision\": prec}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_PATH = \"/kaggle/working/\"\nmodel_name = \"beeImage\"\nstored_model_path = f\"{MODEL_PATH}/{model_name}.p\"\n\ndatagen_params = {\n    \"horizontal_flip\"  : True,\n    \"vertical_flip\"    : True,\n    \"rotation_range\"   : 360,\n    \"brightness_range\" : [.7, 1.]\n}\n\ndatagens = create_datagens(\n    raw_data,\n    datagen_params         = datagen_params,\n    batch_size             = 64, # hyperparameter\n    target_shape           = (50, 54),\n    preprocessing_function = normalize,\n    random_state           = 42\n)\n\ngrid_params = {\n     \"conv__filters_1\" : [32],\n     \"conv__filters_2\" : [48],\n     \"conv__filters_3\" : [64],\n     \"density_units_1\" : [256],\n     \"density_units_2\" : [64],\n     \"batch_size\"      : [64],\n     \"epochs\"          : [50]\n }\n\nbest_original_model = gridSearchCNN(\n     datagens     = datagens,\n     grid_params  = grid_params,\n     random_state = 42,\n     optimizer    = RMSprop(lr = 0.0001, decay = 1e-6),\n     file_name    = f\"{MODEL_PATH}/{model_name}.h5\"\n     )\n\npickle.dump(best_original_model, open(stored_model_path, 'wb')) # saving metadata\n\nbest_original_model = pickle.load(open(stored_model_path, 'rb')) # loading metadata","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}